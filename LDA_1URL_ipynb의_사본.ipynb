{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkimtokyo/LDA/blob/main/LDA_1URL_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이것은 사본입니다.\n",
        "!pip install konlpy\n",
        "!pip install gensim\n",
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "\n",
        "# SudachiPy와 관련된 라이브러리 설치 (일본어 형태소 분석을 위해)\n",
        "!pip install sudachipy\n",
        "!pip install sudachidict_core\n"
      ],
      "metadata": {
        "id": "A_WzioJmo6VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4192046-65fc-4b37-98e0-7306cd820e4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Collecting sudachipy\n",
            "  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sudachipy\n",
            "Successfully installed sudachipy-0.6.8\n",
            "Collecting sudachidict_core\n",
            "  Downloading SudachiDict_core-20240109-py3-none-any.whl (71.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SudachiPy<0.7,>=0.5 in /usr/local/lib/python3.10/dist-packages (from sudachidict_core) (0.6.8)\n",
            "Installing collected packages: sudachidict_core\n",
            "Successfully installed sudachidict_core-20240109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from konlpy.tag import Okt\n",
        "from gensim import corpora, models\n",
        "from sudachipy import tokenizer\n",
        "from sudachipy import dictionary\n",
        "from collections import defaultdict\n",
        "\n",
        "# Corrected raw URLs for stopwords files\n",
        "kr_stopword_url = 'https://raw.githubusercontent.com/your_github_username/your_repository/branch/kr-stopword.txt'\n",
        "jp_stopword_url = 'https://github.com/jkimtokyo/LDA/blob/7c529a3deedf64964a6925c7119dc2cea12ce654/jp-stopword.txt'\n",
        "\n",
        "# Function to download stopwords from the corrected URLs\n",
        "def download_stopwords(url):\n",
        "    response = requests.get(url)\n",
        "    stopwords = response.text.split('\\n')\n",
        "    return [line.strip() for line in stopwords if line.strip()]\n",
        "\n",
        "# Download stopwords using the corrected function\n",
        "kr_stopwords = download_stopwords(kr_stopword_url)\n",
        "jp_stopwords = download_stopwords(jp_stopword_url)\n",
        "\n",
        "# 웹페이지 텍스트 추출 함수\n",
        "def get_text_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    text = soup.get_text(separator=' ', strip=True)\n",
        "    return text\n",
        "\n",
        "# 형태소 분석 및 불용어 처리 함수\n",
        "def analyze_text(lang, text, stopwords):\n",
        "    processed_text = []\n",
        "    if lang == 'kr':\n",
        "        analyzer = Okt()\n",
        "        tokens = analyzer.nouns(text)\n",
        "    elif lang == 'jp':\n",
        "        analyzer = dictionary.Dictionary().create()\n",
        "        mode = tokenizer.Tokenizer.SplitMode.C\n",
        "        tokens = [m.surface() for m in analyzer.tokenize(text, mode)]\n",
        "    processed_text = [word for word in tokens if word not in stopwords and len(word) > 1]\n",
        "    return processed_text\n",
        "\n",
        "# LDA 모델 생성 및 결과 출력 함수, 주요 단어 15개 추출 및 합산\n",
        "def create_lda_model(processed_docs, num_topics=12, num_words=24):\n",
        "    dictionary = corpora.Dictionary(processed_docs)\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
        "\n",
        "    # 모든 토픽에 걸쳐 단어와 스코어를 합산\n",
        "    word_scores = defaultdict(float)\n",
        "    for idx in range(num_topics):\n",
        "        for word, score in lda_model.show_topic(idx, topn=num_words):\n",
        "            word_scores[word] += score\n",
        "\n",
        "    # 합산된 스코어를 기준으로 내림차순 정렬하여 출력\n",
        "    sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    for word, score in sorted_words:\n",
        "        print(f\"{word}: {score:.3f}\")\n",
        "\n",
        "# 메인 실행\n",
        "if __name__ == \"__main__\":\n",
        "    lang = input(\"Enter language (kr for Korean, jp for Japanese): \")\n",
        "    url = input(\"Enter URL: \")\n",
        "    text = get_text_from_url(url)\n",
        "    stopwords = kr_stopwords if lang == 'kr' else jp_stopwords\n",
        "    processed_text = analyze_text(lang, text, stopwords)\n",
        "    processed_docs = [processed_text]\n",
        "    create_lda_model(processed_docs, num_topics=12, num_words=24)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_R78l1OUJ8t",
        "outputId": "b00fd886-d051-4b5f-ad1d-d7882b5816af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter language (kr for Korean, jp for Japanese): jp\n",
            "Enter URL: https://ja.wikipedia.org/wiki/%E9%AB%98%E5%AE%97_(%E6%9C%9D%E9%AE%AE)\n",
            "高宗: 0.026\n",
            "朝鮮: 0.025\n",
            "皇帝: 0.020\n",
            "日本: 0.019\n",
            "いる: 0.018\n",
            "大院: 0.017\n",
            "する: 0.017\n",
            "編集: 0.015\n",
            "国王: 0.014\n",
            "閔妃: 0.014\n",
            "ロシア: 0.014\n",
            "こと: 0.013\n",
            "大韓: 0.013\n",
            "勢力: 0.012\n",
            "この: 0.012\n",
            "政策: 0.011\n",
            "日報: 0.010\n",
            "興宣: 0.010\n",
            "世子: 0.010\n",
            "韓国: 0.010\n",
            "閔氏: 0.009\n",
            "後宮: 0.008\n",
            "帝国: 0.007\n",
            "1947: 0.007\n",
            "動き: 0.004\n",
            "ある: 0.003\n",
            "事件: 0.002\n",
            "独立: 0.002\n",
            "貴人: 0.002\n",
            "1910: 0.002\n",
            "金氏: 0.001\n",
            "政治: 0.001\n",
            "1897: 0.001\n",
            "1919: 0.001\n",
            "ため: 0.001\n",
            "12: 0.001\n",
            "哲宗: 0.001\n",
            "記事: 0.001\n",
            "ページ: 0.001\n",
            "から: 0.001\n",
            "指定: 0.001\n",
            "より: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nes3unxYuZW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}